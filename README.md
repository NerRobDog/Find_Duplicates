# Поиск Дубликатов Файлов на Python

## Оглавление

1. [Введение](#введение)
2. [Цель Проекта](#цель-проекта)
3. [Требования](#требования)
4. [Архитектура Проекта](#архитектура-проекта)
5. [Этапы Разработки](#этапы-разработки)
    - [1. Сбор и Фильтрация Файлов](#1-сбор-и-фильтрация-файлов)
    - [2. Группировка Файлов по Размеру](#2-группировка-файлов-по-размеру)
    - [3. Сравнение Частичного Содержимого](#3-сравнение-частичного-содержимого)
    - [4. Вычисление и Сравнение Хэшей](#4-вычисление-и-сравнение-хэшей)
    - [5. Побайтовое Сравнение](#5-побайтовое-сравнение)
    - [6. Форматирование и Вывод Результатов](#6-форматирование-и-вывод-результатов)
6. [Используемые Технологии и Библиотеки](#используемые-технологии-и-библиотеки)
    - [Стандартные Библиотеки](#стандартные-библиотеки)
    - [Дополнительные Библиотеки](#дополнительные-библиотеки)
7. [Описание Используемых Инструментов и Библиотек](#описание-используемых-инструментов-и-библиотек)
    - [`os` и `pathlib`](#os-и-pathlib)
    - [`fnmatch` и `re`](#fnmatch-и-re)
    - [`hashlib`](#hashlib)
    - [`argparse`](#argparse)
    - [`csv`](#csv)
    - [`logging`](#logging)
    - [`concurrent.futures`](#concurrentfutures)
    - [`tqdm`](#tqdm)
8. [Оптимизации и Алгоритмы](#оптимизации-и-алгоритмы)
9. [Тестирование и Валидация](#тестирование-и-валидация)
10. [Инструкции по Установке и Использованию](#инструкции-по-установке-и-использованию)
11. [Дополнительные Возможности](#дополнительные-возможности)
12. [Лицензия](#лицензия)

---

## Введение

Поиск дубликатов файлов является важной задачей для управления файловой системой, освобождения места на диске и повышения эффективности работы. Существующие утилиты, такие как `rdfind`, сталкиваются с рядом ограничений при обработке больших объёмов данных и сложных условий исключения файлов. Цель данного проекта — разработать собственное Python-приложение для поиска дубликатов файлов, которое будет эффективно обрабатывать большие директории, поддерживать гибкие условия исключения и предоставлять удобные результаты.

## Цель Проекта

Создать Python-приложение для поиска дубликатов файлов в больших директориях с учётом следующих требований:

- Полное сравнение всех файлов без разбиения на группы.
- Избежание переполнения командной строки.
- Эффективное управление памятью и временными файлами.
- Обработка исключений для скрытых и системных файлов.
- Поддержка нескольких типов хэшей (MD5, SHA1, SHA256, SHA512).
- Побайтовое сравнение для подтверждения дубликатов.
- Вывод результатов в удобном табличном формате.

## Требования

- **Язык программирования:** Python 3.6+
- **Операционные системы:** Linux, macOS, Windows
- **Зависимости:** Стандартные библиотеки Python и дополнительные библиотеки (например, `tqdm` для прогресс-баров)

## Архитектура Проекта

Проект будет состоять из следующих компонентов:

1. **Модуль Парсинга Аргументов:** Обработка аргументов командной строки с помощью `argparse`.
2. **Модуль Сканирования Файлов:** Рекурсивный обход директории с фильтрацией по шаблонам исключений.
3. **Модуль Сравнения Файлов:** Группировка по размеру, сравнение частичного содержимого, вычисление хэшей, побайтовое сравнение.
4. **Модуль Управления Результатами:** Сохранение результатов в формате CSV, логирование процесса.
5. **Модуль Оптимизации:** Реализация многопоточности для ускорения вычислений.

## Этапы Разработки

### 1. Сбор и Фильтрация Файлов

**Задачи:**

- Рекурсивный обход целевой директории.
- Исключение файлов и директорий по заданным шаблонам (например, скрытые файлы, `.DS_Store`, `node_modules`, `.git`).

**Инструменты:**

- Модули `os`, `pathlib`, `fnmatch` для работы с файловой системой и фильтрации.

**Рекомендации:**

- Использовать генераторы для итеративного обхода файлов, чтобы снизить потребление памяти.
- Реализовать гибкую систему исключений через аргументы командной строки.

### 2. Группировка Файлов по Размеру

**Задачи:**

- Группировать файлы с одинаковым размером, так как дубликаты обязательно имеют одинаковый размер.

**Инструменты:**

- Использование `defaultdict` для группировки файлов по размеру.

**Рекомендации:**

- Пропускать группы с одним файлом, так как дубликатов нет.

### 3. Сравнение Частичного Содержимого

**Задачи:**

- Быстрое предварительное сравнение файлов с одинаковым размером путем сравнения начальных и конечных байтов.

**Инструменты:**

- Чтение первых и последних N байтов (например, 1 КБ) файла.

**Рекомендации:**

- Если частичные данные совпадают, переходить к более тщательному сравнению (хэшам и побайтовому).

### 4. Вычисление и Сравнение Хэшей

**Задачи:**

- Вычислить хэш (MD5, SHA1, SHA256, SHA512) для файлов, прошедших предыдущие этапы.
- Сравнить хэши для идентификации потенциальных дубликатов.

**Инструменты:**

- Модуль `hashlib` для вычисления хэшей.
- Поддержка выбора типа хэша через аргументы командной строки.

**Рекомендации:**

- Вычислять хэш только если предыдущие сравнения дали положительный результат.
- Реализовать параллельное вычисление хэшей для ускорения процесса с использованием `concurrent.futures`.

### 5. Побайтовое Сравнение

**Задачи:**

- Подтвердить, что файлы с одинаковыми хэшами действительно идентичны.

**Инструменты:**

- Побайтовое чтение и сравнение двух файлов.

**Рекомендации:**

- Реализовать оптимизированное чтение файлов по блокам (например, 4 КБ) для эффективного сравнения.
- Прекращать сравнение при первом обнаружении различий.

### 6. Форматирование и Вывод Результатов

**Задачи:**

- Сохранить результаты поиска дубликатов в удобном формате (например, CSV).

**Инструменты:**

- Модуль `csv` для записи результатов.
- Модуль `logging` для ведения логов и отслеживания процесса.

**Рекомендации:**

- Добавить опции для выбора формата вывода.
- Включить информацию о группах дубликатов для удобства анализа.

## Используемые Технологии и Библиотеки

### Стандартные Библиотеки

- `os`, `pathlib`: Работа с файловой системой.
- `fnmatch`, `re`: Обработка шаблонов исключений.
- `hashlib`: Вычисление хэшей.
- `argparse`: Парсинг аргументов командной строки.
- `csv`: Запись результатов.
- `logging`: Ведение логов.
- `concurrent.futures`: Параллельная обработка.

### Дополнительные Библиотеки

- `tqdm`: Отображение прогресс-баров для улучшения пользовательского опыта.

## Описание Используемых Инструментов и Библиотек

### `os` и `pathlib`

- **Описание:** Модули для взаимодействия с операционной системой, предоставляющие функции для работы с файловой системой, путями к файлам и директориям.
- **Документация:**
  - [os — Общие операционные системы интерфейсы](https://docs.python.org/3/library/os.html)
  - [pathlib — Объектно-ориентированные пути файловой системы](https://docs.python.org/3/library/pathlib.html)

### `fnmatch` и `re`

- **Описание:** Модули для сопоставления строк с шаблонами и регулярными выражениями, используемые для фильтрации файлов и директорий по заданным условиям.
- **Документация:**
  - [fnmatch — Сопоставление с шаблонами](https://docs.python.org/3/library/fnmatch.html)
  - [re — Регулярные выражения](https://docs.python.org/3/library/re.html)

### `hashlib`

- **Описание:** Модуль для создания хэш-значений различных алгоритмов, таких как MD5, SHA1, SHA256 и SHA512, используемых для проверки целостности и идентичности файлов.
- **Документация:**
  - [hashlib — Безопасные хэш-алгоритмы и криптографические хэш-функции](https://docs.python.org/3/library/hashlib.html)

### `argparse`

- **Описание:** Модуль для парсинга аргументов командной строки, позволяющий создавать гибкие и удобные интерфейсы для CLI-приложений.
- **Документация:**
  - [argparse — Парсинг аргументов командной строки](https://docs.python.org/3/library/argparse.html)

### `csv`

- **Описание:** Модуль для чтения и записи файлов в формате CSV, используемый для сохранения результатов поиска дубликатов в табличном виде.
- **Документация:**
  - [csv — Чтение и запись файлов в формате CSV](https://docs.python.org/3/library/csv.html)

### `logging`

- **Описание:** Модуль для реализации гибкой системы логирования, позволяющий отслеживать процесс выполнения скрипта и фиксировать ошибки.
- **Документация:**
  - [logging — Система логирования](https://docs.python.org/3/library/logging.html)

### `concurrent.futures`

- **Описание:** Модуль для упрощённой параллельной обработки задач с использованием потоков или процессов, что позволяет ускорить вычисления хэшей и сравнения файлов.
- **Документация:**
  - [concurrent.futures — Высокоуровневые интерфейсы для асинхронного выполнения](https://docs.python.org/3/library/concurrent.futures.html)

### `tqdm`

- **Описание:** Библиотека для отображения прогресс-баров в консоли, улучшает пользовательский опыт, предоставляя визуальную обратную связь о ходе выполнения скрипта.
- **Документация:**
  - [tqdm — Быстрый, расширяемый прогресс-бар для циклов](https://tqdm.github.io/)

## Оптимизации и Алгоритмы

### Эффективный Обход Файловой Системы

- **Использование Генераторов:** Применение генераторов (`yield`) для итерации по файлам снижает потребление памяти и повышает производительность.
- **Исключение на Этапе Обхода:** Фильтрация ненужных файлов и директорий уже при обходе, чтобы не тратить ресурсы на их дальнейшую обработку.

### Группировка и Фильтрация

- **Группировка по Размеру:** Первичная группировка файлов по размеру позволяет быстро исключить файлы, которые не могут быть дубликатами.
- **Частичное Сравнение:** Сравнение начальных и конечных байтов файла ускоряет процесс, отбрасывая несоответствующие файлы до вычисления хэшей.

### Параллельная Обработка

- **Многопоточность и Многопроцессность:** Использование `concurrent.futures` для параллельного вычисления хэшей и сравнения файлов значительно ускоряет процесс, особенно на многоядерных системах.

### Управление Памятью

- **Использование Итераторов:** Применение итераторов и генераторов позволяет эффективно обрабатывать большие наборы файлов без загрузки всех данных в память одновременно.
- **Минимизация Временных Файлов:** Использование внутренних структур данных вместо временных файлов снижает нагрузку на диск и ускоряет процесс.

### Обработка Исключений

- **Гибкие Шаблоны Исключений:** Реализация поддержки различных шаблонов исключений позволяет пользователям настраивать фильтрацию под свои нужды.
- **Обработка Ошибок Доступа:** Логирование и игнорирование ошибок доступа к файлам гарантирует, что скрипт продолжит работу даже при наличии проблем с отдельными файлами.

## Тестирование и Валидация

### Юнит-тесты

- **Тестирование Функций Сбора и Фильтрации Файлов:** Проверка корректности обхода и исключения файлов.
- **Тестирование Функций Вычисления Хэшей:** Убедиться в правильности и надежности вычисления хэшей различных типов.
- **Тестирование Функций Сравнения Файлов:** Проверка точности и эффективности побайтового сравнения.

### Интеграционные Тесты

- **Проверка Полного Процесса:** Тестирование всего процесса на небольших наборах файлов для уверенности в правильности работы.
- **Тестирование Исключений и Шаблонов:** Убедиться, что скрипт правильно обрабатывает заданные шаблоны исключений.

### Производительность

- **Тестирование на Больших Наборах Файлов:** Оценка времени выполнения и использования ресурсов при обработке больших объемов данных (например, 50,000+ файлов).
- **Оптимизация Алгоритмов:** Анализ и улучшение алгоритмов для снижения времени обработки и потребления памяти.

## Инструкции по Установке и Использованию

### Установка

1. **Клонирование Репозитория:**
    ```bash
    git clone https://github.com/ваш-репозиторий/find_duplicates.git
    cd find_duplicates
    ```

2. **Установка Зависимостей:**
    ```bash
    pip install -r requirements.txt
    ```

### Использование

```bash
python find_duplicates.py <путь_к_директории> [опции]
```
#### Пример использования:
```
python find_duplicates.py /run/media/rocky/Films -e ".*" ".DS_Store" "*.tmp" "Thumbs.db" "node_modules" ".git" -ht sha256 -o duplicates_Films.csv
```
### Описание Опций:
* -e, --exclude: Шаблоны для исключения файлов и директорий (например, `*.tmp, .*`).
* -ht, --hash-type: Тип хэша для сравнения (md5, sha1, sha256, sha512). По умолчанию sha1.
* -o, --output: Имя выходного CSV файла. По умолчанию duplicates.csv.

### Дополнительные Возможности
1. Удаление или Перемещение Дубликатов:
* Добавить опции для автоматического удаления дубликатов или их перемещения в указанную директорию после подтверждения.
2. Графический Интерфейс Пользователя (GUI):
Разработка GUI для более удобного использования скрипта. 
3.Интеграция с Базами Данных:
* Для хранения и быстрого поиска информации о файлах.
* Поиск информации о дубликатах в базах данных.
4. Поддержка Web Сценариев и API:4. Поддержка Облачных Хранилищ:
Расширение функционала для работы с облачными сервисами (например, AWS S3, Google Drive).
5. Параметры Оптимизации:
* Настройка размера блоков для побайтового сравнения.
* Выбор пороговых значений для этапов сравнения.
